#!/usr/bin/env python3
"""
Stage 4: ì¢Œí‘œê³„ ë¹„êµ ì‹œê°í™”ì™€ ê²°ê³¼ ì €ì¥
- Stage 3 ê¸°ëŠ¥ í¬í•¨
- 3ê°œ ì¢Œí‘œê³„ ë™ì‹œ ë¹„êµ ì‹œê°í™” ì¶”ê°€
- ê²°ê³¼ ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€

ìƒˆë¡œìš´ í•™ìŠµ í¬ì¸íŠ¸:
- ì¢Œí‘œê³„ ë³€í™˜ ê²€ì¦
- 3ê°œ ì¢Œí‘œê³„ ë™ì‹œ ë¹„êµ
- í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì €ì¥ (PLY í˜•ì‹)
"""

import os
import sys
import time
import json
from pathlib import Path
import numpy as np
from scipy.spatial.transform import Rotation
import cv2
from typing import Tuple, Dict, Any

# Qt í”Œë«í¼ ì¶©ëŒ ë°©ì§€
import matplotlib
if 'DISPLAY' in os.environ:
    try:
        matplotlib.use('TkAgg')
    except (ImportError, RuntimeError) as e:
        matplotlib.use('Agg')
else:
    matplotlib.use('Agg')

# Open3D import
try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    print("Warning: Open3D not installed. 3D visualization will be limited.")
    HAS_OPEN3D = False

# utilsë¥¼ ìœ„í•œ ìƒìœ„ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))
from utils import camera_utils, transform_utils

# ====================================
# ë°ì´í„° ê²½ë¡œ ì„¤ì •
# ====================================
DATA_BASE_PATH = Path(__file__).parent.parent / "lecture-standalone" / "replicator_output" / "advanced_dataset" / "Replicator_04"

def print_step(step_num: int, description: str) -> float:
    """ë‹¨ê³„ë³„ ì¶œë ¥ í—¬í¼"""
    print(f"\n[Step {step_num}] {description}...")
    return time.time()

def print_done(start_time: float, details: str = "") -> None:
    """ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥"""
    elapsed = time.time() - start_time
    print(f"âœ“ ì™„ë£¼ ({elapsed:.3f}ì´ˆ) {details}")

# ====================================
# Stage 1-3 ê¸°ëŠ¥ë“¤ (ì¬ì‚¬ìš©)
# ====================================
def load_data(frame_id: int = 53) -> Tuple[np.ndarray, np.ndarray]:
    """RGB-D ë°ì´í„° ë¡œë“œ"""
    rgb_path = DATA_BASE_PATH / "rgb" / f"rgb_{frame_id:04d}.png"
    depth_path = DATA_BASE_PATH / "distance_to_image_plane" / f"distance_to_image_plane_{frame_id:04d}.npy"
    
    rgb_image = cv2.imread(str(rgb_path))
    rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)
    depth_map = np.load(str(depth_path))
    
    print(f"  RGB shape: {rgb_image.shape}")
    print(f"  Depth shape: {depth_map.shape}")
    
    return rgb_image, depth_map

def depth_to_pointcloud(depth_map: np.ndarray, rgb_image: np.ndarray, intrinsics) -> Tuple[np.ndarray, np.ndarray]:
    """2D â†’ 3D ì¹´ë©”ë¼ ì¢Œí‘œ ë³€í™˜"""
    height, width = depth_map.shape
    u_grid, v_grid = np.meshgrid(np.arange(width), np.arange(height))
    
    z = depth_map
    x = (u_grid - intrinsics.cx) * z / intrinsics.fx
    y = (v_grid - intrinsics.cy) * z / intrinsics.fy
    
    points_3d = np.stack([x, y, z], axis=-1).reshape(-1, 3)
    colors = rgb_image.reshape(-1, 3)
    
    valid_mask = depth_map.flatten() > 0
    return points_3d[valid_mask], colors[valid_mask]

def get_camera_pose() -> Dict[str, Any]:
    """ì¹´ë©”ë¼ í¬ì¦ˆ ì •ì˜"""
    cam_rotation_x = np.array([[1, 0, 0], [0, 0, -1], [0, 1, 0]])
    cam_rotation_z = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])
    cam_rotation = cam_rotation_x @ cam_rotation_z
    
    r = Rotation.from_matrix(cam_rotation)
    camera_quaternion = r.as_quat()
    
    return {
        'position': np.array([0.5, 1.5, 0.0]),
        'orientation': camera_quaternion
    }

def transform_camera_to_world(points_camera: np.ndarray, camera_pose: Dict[str, Any]) -> np.ndarray:
    """ì¹´ë©”ë¼ â†’ ì›”ë“œ ì¢Œí‘œ ë³€í™˜"""
    T = transform_utils.create_transformation_matrix(
        camera_pose['orientation'],
        camera_pose['position']
    )
    
    points_homogeneous = np.hstack([
        points_camera,
        np.ones((len(points_camera), 1))
    ])
    
    points_world_homogeneous = points_homogeneous @ T.T
    return points_world_homogeneous[:, :3]

def isaac_to_ros_points(points_isaac: np.ndarray) -> np.ndarray:
    """Isaac Sim â†’ ROS ì¢Œí‘œ ë³€í™˜"""
    points_ros = np.zeros_like(points_isaac)
    points_ros[:, 0] = points_isaac[:, 0]
    points_ros[:, 1] = -points_isaac[:, 2]
    points_ros[:, 2] = points_isaac[:, 1]
    return points_ros

# ====================================
# â˜… Step 8 - ì¢Œí‘œê³„ ë¹„êµ ì‹œê°í™”
# ====================================
def visualize_comparison(points_camera: np.ndarray, points_world: np.ndarray, points_ros: np.ndarray) -> None:
    """
    3ê°œ ì¢Œí‘œê³„ ë™ì‹œ ë¹„êµ ì‹œê°í™”
    
    í•™ìŠµ í¬ì¸íŠ¸:
    - ë¹¨ê°„ìƒ‰: ì¹´ë©”ë¼ ì¢Œí‘œê³„
    - ì´ˆë¡ìƒ‰: ì›”ë“œ ì¢Œí‘œê³„ (Isaac Sim)
    - íŒŒë€ìƒ‰: ROS ì¢Œí‘œê³„
    - ê° ì¢Œí‘œê³„ë¥¼ ì˜†ìœ¼ë¡œ ë°°ì¹˜í•˜ì—¬ ë¹„êµ
    """
    
    if not HAS_OPEN3D:
        print("  Open3Dê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë¹„êµ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print("\n[ì¢Œí‘œê³„ ë¹„êµ ì‹œê°í™”]")
    print("  ë¹¨ê°„ìƒ‰: ì¹´ë©”ë¼ ì¢Œí‘œê³„ (ì›ì ì´ ì¹´ë©”ë¼)")
    print("  ì´ˆë¡ìƒ‰: ì›”ë“œ ì¢Œí‘œê³„ (Isaac Sim Y-up)")
    print("  íŒŒë€ìƒ‰: ROS ì¢Œí‘œê³„ (Z-up)")
    print("\n  ê° ì¢Œí‘œê³„ë¥¼ 1mì”© ì˜†ìœ¼ë¡œ ë°°ì¹˜í•˜ì—¬ ë¹„êµ")
    
    geometries = []
    
    # ì¹´ë©”ë¼ ì¢Œí‘œê³„ (ë¹¨ê°„ìƒ‰) - ìœ„ì¹˜ ê·¸ëŒ€ë¡œ
    pcd_camera = o3d.geometry.PointCloud()
    pcd_camera.points = o3d.utility.Vector3dVector(points_camera)
    pcd_camera.paint_uniform_color([1, 0.2, 0.2])  # ë¹¨ê°„ìƒ‰
    geometries.append(pcd_camera)
    
    # ì¹´ë©”ë¼ ì¢Œí‘œì¶•
    axes_camera = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3)
    geometries.append(axes_camera)
    
    # ì›”ë“œ ì¢Œí‘œê³„ (ì´ˆë¡ìƒ‰) - ì˜¤ë¥¸ìª½ìœ¼ë¡œ 2m ì´ë™
    pcd_world = o3d.geometry.PointCloud()
    pcd_world.points = o3d.utility.Vector3dVector(points_world + np.array([2, 0, 0]))
    pcd_world.paint_uniform_color([0.2, 1, 0.2])  # ì´ˆë¡ìƒ‰
    geometries.append(pcd_world)
    
    # ì›”ë“œ ì¢Œí‘œì¶•
    axes_world = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3)
    axes_world.translate([2, 0, 0])
    geometries.append(axes_world)
    
    # ROS ì¢Œí‘œê³„ (íŒŒë€ìƒ‰) - ì˜¤ë¥¸ìª½ìœ¼ë¡œ 4m ì´ë™
    pcd_ros = o3d.geometry.PointCloud()
    pcd_ros.points = o3d.utility.Vector3dVector(points_ros + np.array([4, 0, 0]))
    pcd_ros.paint_uniform_color([0.2, 0.2, 1])  # íŒŒë€ìƒ‰
    geometries.append(pcd_ros)
    
    # ROS ì¢Œí‘œì¶•
    axes_ros = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3)
    axes_ros.translate([4, 0, 0])
    geometries.append(axes_ros)
    
    # ë¼ë²¨ ì¶”ê°€ (êµ¬ì²´ë¡œ í‘œì‹œ)
    sphere_camera = o3d.geometry.TriangleMesh.create_sphere(radius=0.05)
    sphere_camera.translate([0, -0.5, 0])
    sphere_camera.paint_uniform_color([1, 0, 0])
    geometries.append(sphere_camera)
    
    sphere_world = o3d.geometry.TriangleMesh.create_sphere(radius=0.05)
    sphere_world.translate([2, -0.5, 0])
    sphere_world.paint_uniform_color([0, 1, 0])
    geometries.append(sphere_world)
    
    sphere_ros = o3d.geometry.TriangleMesh.create_sphere(radius=0.05)
    sphere_ros.translate([4, -0.5, 0])
    sphere_ros.paint_uniform_color([0, 0, 1])
    geometries.append(sphere_ros)
    
    # ì‹œê°í™”
    o3d.visualization.draw_geometries(
        geometries,
        window_name="Stage 4: Coordinate Systems Comparison",
        width=1280, height=720,
        point_show_normal=False
    )

# ====================================
# â˜… Step 9 - ê²°ê³¼ ì €ì¥
# ====================================
def save_results(points_camera: np.ndarray, points_world: np.ndarray, points_ros: np.ndarray, colors: np.ndarray, camera_pose: Dict[str, Any], frame_id: int) -> None:
    """
    ë³€í™˜ ê²°ê³¼ ì €ì¥
    
    ì €ì¥ ë‚´ìš©:
    - PLY íŒŒì¼: 3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
    - NPY íŒŒì¼: NumPy ë°°ì—´
    - JSON íŒŒì¼: í†µê³„ì™€ ë©”íƒ€ë°ì´í„°
    """
    
    print("\n[ê²°ê³¼ ì €ì¥]")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = Path("output")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. PLY íŒŒì¼ ì €ì¥ (3D í¬ì¸íŠ¸ í´ë¼ìš°ë“œ)
    if HAS_OPEN3D:
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points_ros)
        if colors is not None:
            pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)
        
        ply_path = output_dir / f"pointcloud_frame{frame_id:04d}.ply"
        o3d.io.write_point_cloud(str(ply_path), pcd)
        print(f"  âœ“ PLY ì €ì¥: {ply_path}")
    
    # 2. NumPy ë°°ì—´ ì €ì¥
    np_path = output_dir / "points_ros.npy"
    np.save(str(np_path), points_ros)
    print(f"  âœ“ NumPy ì €ì¥: {np_path}")
    
    # 3. í†µê³„ JSON ì €ì¥
    stats = {
        'frame_id': frame_id,
        'num_points': len(points_camera),
        'centroid_camera': points_camera.mean(axis=0).tolist(),
        'centroid_world': points_world.mean(axis=0).tolist(),
        'centroid_ros': points_ros.mean(axis=0).tolist(),
        'camera_pose': {
            'position': camera_pose['position'].tolist(),
            'orientation': camera_pose['orientation'].tolist()
        },
        'coordinate_systems': {
            'camera': 'X=right, Y=down, Z=forward',
            'world': 'Isaac Sim Y-up: X=right, Y=up, Z=forward',
            'ros': 'Z-up: X=forward, Y=left, Z=up'
        }
    }
    
    stats_path = output_dir / "transform_stats.json"
    with open(stats_path, 'w') as f:
        json.dump(stats, f, indent=2)
    print(f"  âœ“ í†µê³„ ì €ì¥: {stats_path}")
    
    return stats

# ====================================
# â˜… Step 10 - ìµœì¢… ìš”ì•½
# ====================================
def print_summary(stats: Dict[str, Any]) -> None:
    """
    ë³€í™˜ ê²°ê³¼ ìš”ì•½
    
    í•™ìŠµ í¬ì¸íŠ¸:
    - ê° ì¢Œí‘œê³„ì˜ íŠ¹ì„± í™•ì¸
    - ë³€í™˜ì˜ ì •í™•ì„± ê²€ì¦
    - í…Œì´ë¸” ë†’ì´ ë“± ì£¼ìš” ì§€í‘œ
    """
    
    print(f"\n{'=' * 60}")
    print("ë³€í™˜ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    
    print(f"\nì´ í¬ì¸íŠ¸ ìˆ˜: {stats['num_points']:,}")
    
    print("\nì¤‘ì‹¬ì  ë¹„êµ:")
    print(f"  ì¹´ë©”ë¼: [{stats['centroid_camera'][0]:.3f}, "
          f"{stats['centroid_camera'][1]:.3f}, "
          f"{stats['centroid_camera'][2]:.3f}]")
    print(f"  ì›”ë“œ:   [{stats['centroid_world'][0]:.3f}, "
          f"{stats['centroid_world'][1]:.3f}, "
          f"{stats['centroid_world'][2]:.3f}]")
    print(f"  ROS:    [{stats['centroid_ros'][0]:.3f}, "
          f"{stats['centroid_ros'][1]:.3f}, "
          f"{stats['centroid_ros'][2]:.3f}]")
    
    print("\nì£¼ìš” í™•ì¸ ì‚¬í•­:")
    print(f"  âœ“ ì¹´ë©”ë¼ Z (ê¹Šì´): {stats['centroid_camera'][2]:.3f}m")
    print(f"  âœ“ ì›”ë“œ Y (ë†’ì´):   {stats['centroid_world'][1]:.3f}m")
    print(f"  âœ“ ROS Z (ë†’ì´):    {stats['centroid_ros'][2]:.3f}m")
    
    # í…Œì´ë¸” ë†’ì´ëŠ” ì•½ 0.38m
    expected_table_height = 0.38
    ros_z = stats['centroid_ros'][2]
    error = abs(ros_z - expected_table_height)
    
    if error < 0.05:
        print(f"\n  âœ… í…Œì´ë¸” ë†’ì´ ê²€ì¦: {ros_z:.3f}m (ì˜ˆìƒ: {expected_table_height}m)")
    else:
        print(f"\n  âš ï¸ í…Œì´ë¸” ë†’ì´ í™•ì¸ í•„ìš”: {ros_z:.3f}m (ì˜ˆìƒ: {expected_table_height}m)")

# ====================================
# ë©”ì¸ í•¨ìˆ˜
# ====================================
def main() -> None:
    """Stage 4 ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("=" * 60)
    print("Stage 4: ì¢Œí‘œê³„ ë¹„êµì™€ ê²°ê³¼ ì €ì¥")
    print("=" * 60)
    print("\ní•™ìŠµ ëª©í‘œ:")
    print("  1. 3ê°œ ì¢Œí‘œê³„ ë™ì‹œ ë¹„êµ")
    print("  2. ë³€í™˜ ê²°ê³¼ ê²€ì¦")
    print("  3. í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì €ì¥")
    
    # Step 1: ë°ì´í„° ë¡œë“œ
    t = print_step(1, "RGB-D ë°ì´í„° ë¡œë“œ ì¤‘")
    frame_id = 53
    rgb_image, depth_map = load_data(frame_id)
    print_done(t)
    
    # Step 2: 3D ë³€í™˜
    t = print_step(2, "3D ë³€í™˜ ì¤‘")
    intrinsics = camera_utils.CameraIntrinsics()
    points_camera, colors = depth_to_pointcloud(depth_map, rgb_image, intrinsics)
    print(f"  ìƒì„±ëœ í¬ì¸íŠ¸: {len(points_camera):,}ê°œ")
    print_done(t)
    
    # Step 3: ì¹´ë©”ë¼ â†’ ì›”ë“œ ë³€í™˜
    t = print_step(3, "ì¹´ë©”ë¼ â†’ ì›”ë“œ ì¢Œí‘œ ë³€í™˜")
    camera_pose = get_camera_pose()
    points_world = transform_camera_to_world(points_camera, camera_pose)
    print_done(t)
    
    # Step 4: Isaac Sim â†’ ROS ë³€í™˜
    t = print_step(4, "Isaac Sim â†’ ROS ì¢Œí‘œ ë³€í™˜")
    points_ros = isaac_to_ros_points(points_world)
    print_done(t)
    
    # â˜… Step 5: ì¢Œí‘œê³„ ë¹„êµ ì‹œê°í™” (NEW)
    if HAS_OPEN3D:
        t = print_step(5, "ì¢Œí‘œê³„ ë¹„êµ ì‹œê°í™”")
        visualize_comparison(points_camera, points_world, points_ros)
        print_done(t)
    
    # â˜… Step 6: ìµœì¢… ROS ì¢Œí‘œê³„ ì‹œê°í™”
    if HAS_OPEN3D:
        t = print_step(6, "ìµœì¢… ROS ì¢Œí‘œê³„ ì‹œê°í™”")
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points_ros)
        if colors is not None:
            pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)
        
        axes = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5)
        
        o3d.visualization.draw_geometries(
            [pcd, axes],
            window_name="Stage 4: Final ROS Point Cloud",
            width=1024, height=768
        )
        print_done(t)
    
    # â˜… Step 7: ê²°ê³¼ ì €ì¥ (NEW)
    t = print_step(7, "ê²°ê³¼ ì €ì¥ ì¤‘")
    stats = save_results(points_camera, points_world, points_ros, colors, camera_pose, frame_id)
    print_done(t)
    
    # â˜… Step 8: ìµœì¢… ìš”ì•½ (NEW)
    print_summary(stats)
    
    # ì™„ë£Œ
    print(f"\n{'=' * 60}")
    print("âœ“ Stage 4 ì™„ë£Œ! (ì „ì²´ íŒŒì´í”„ë¼ì¸)")
    print("=" * 60)
    print("\nì „ì²´ ë³€í™˜ ì²´ì¸:")
    print("  1. í”½ì…€ + ê¹Šì´ â†’ ì¹´ë©”ë¼ 3D (Pinhole model)")
    print("  2. ì¹´ë©”ë¼ 3D â†’ ì›”ë“œ 3D (4x4 ë³€í™˜)")
    print("  3. ì›”ë“œ 3D â†’ ROS 3D (ì¢Œí‘œê³„ ë³€í™˜)")
    print("\nì €ì¥ëœ íŒŒì¼:")
    print("  â€¢ output/stage4_pointcloud_frame0053.ply")
    print("  â€¢ output/stage4_points_ros.npy")
    print("  â€¢ output/stage4_transform_stats.json")
    print("\nğŸ‰ ì¢Œí‘œ ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì‹¤ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    main()